{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Capstone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2852a2df3fb7445aa91d7033ad63f849"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22a441aab624e6d95c48e72caa5479f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef54f3acee64d2391f03137082c94a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6048e21ccb4ed0b9cf377cf0b4ed99"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41ef74fe11a408d811cd3e83f923323"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205fa3076ed74558af8db0a90863009b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604395c7ed144102916cd0eb55d06875"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de94c5add33843cabe25eb7d22853849"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eef516c83a64509aa81dc2b2cec973f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13732df7985d432e84b1472ecc87c867"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "265e39469a0545ecbed56ea11a55fcd1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d011e9b9524b6a81e78cdbdacb31ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d2dd085fbc4e09b661a77f4353eaf8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d59f02b817e4cbbb591229fb86254ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc67bc69b7764f158da27094f74cc4db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbc31681e7f4bc29be5695faa6be63e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60d9e0c7a8144d69ed2c5000072cf1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45efd6d86f5b4672ac19e0d79fbbf05e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134e438798684992805ffb06ead02ff5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6718953cf814e5fbfaa9eb595117a7b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d9cd4a15a54863a5a0d4da81fa7b19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe58090eb4c4f11ace0bc8e49abc96b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc7961f7a0148d2abc49ed63ce7fc72"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd2684bd78f4a37a8d3bf9a2bb16d12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2551371d90d64bdda9038af70012fb23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e5241294924f8784e0d6f88b833584"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805aa08feb064aa78ad6a28ed150be77"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d778a93869774006826111ea438694bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924f6e4c5fc443e69cae34820785e2e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab31f84bdaf34c20a8c534a840159e59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f95c5393b7f475b90458a95b6e0777d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ae16fbddb048c08ad5f8b3782a2abf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d78e847b2146b8aa909f16c3bcc398"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e08e9030e74054bf48923ec05cc3ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "# returns the number of secs in video\n",
    "def video_length(path):\n",
    "    cmd = \"ffprobe -i \" + path + \" -show_entries format=duration -v quiet -of json\"\n",
    "    pipe = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE).stdout\n",
    "    output = pipe.read()\n",
    "    d = json.loads(output)\n",
    "    s = d[\"format\"][\"duration\"]\n",
    "    return int(float(s))\n",
    "\n",
    "# returns the id of a video in the ./data/videos dir\n",
    "def video_id(path):\n",
    "    return path.split(\"/\")[3].split(\".\")[0]\n",
    "\n",
    "def clip_dir_path(path):\n",
    "    vid_id = video_id(path)\n",
    "    return \"./data/clips/\" + vid_id\n",
    "\n",
    "# creates a folder with one sec clips from the source video\n",
    "# takes about 30 mins for a 20 min video\n",
    "def create_clips(path):\n",
    "    # create clip dir\n",
    "    dir_path = clip_dir_path(path)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    \n",
    "    # create one sec clips from src\n",
    "    video_len = video_length(path)\n",
    "    for i in tqdm_notebook(xrange(video_len), desc=\"Clips for \" + video_id(path)):\n",
    "        clip_path = dir_path + \"/\" + '%05d' % i + \".mp4\"    \n",
    "        if not os.path.exists(clip_path):\n",
    "            cmd = \"ffmpeg -v error -y -i \" + path + \" -ss \" + str(i) + \" -t 1 \" + clip_path\n",
    "            os.system(cmd)\n",
    "\n",
    "# creates folders with frames for each clip of source video\n",
    "def create_frames(path):\n",
    "    # create frame dir\n",
    "    vid_id = video_id(path)\n",
    "    dir_path = \"./data/frames/\" + vid_id\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    \n",
    "    # create frames from clip\n",
    "    video_len = video_length(path)\n",
    "    for i in tqdm_notebook(xrange(video_len), desc=\"Frames for \" + vid_id):\n",
    "        clip_path = clip_dir_path(path) + \"/\" + '%05d' % i + \".mp4\"\n",
    "        frame_dir_path = dir_path + \"/\" + '%05d' % i\n",
    "        if not os.path.exists(frame_dir_path):\n",
    "            os.makedirs(frame_dir_path)\n",
    "            cmd = \"ffmpeg -v error -y -i \" + clip_path + \" -r 5.0 \" + frame_dir_path + \"/%5d.jpg\"\n",
    "            os.system(cmd)\n",
    "\n",
    "def create_spectrograms(path):\n",
    "    # create audio dir\n",
    "    vid_id = video_id(path)\n",
    "    dir_path = \"./data/audio/\" + vid_id\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    \n",
    "    # create spectrogram from clip\n",
    "    video_len = video_length(path)\n",
    "    for i in tqdm_notebook(xrange(video_len), desc=\"Spectrograms for \" + vid_id):\n",
    "        clip_path = clip_dir_path(path) + \"/\" + '%05d' % i + \".mp4\"\n",
    "        spec_path = dir_path + \"/\" + '%05d' % i + \".png\"\n",
    "        if not os.path.exists(spec_path):\n",
    "            cmd = \"ffmpeg -v error -y -i \" + clip_path + \" -lavfi showspectrumpic=s=32x32:legend=false \" + spec_path\n",
    "            os.system(cmd)\n",
    "            \n",
    "        \n",
    "video_paths = glob.glob(\"./data/videos/*.mp4\")\n",
    "videos_len = len(video_paths)\n",
    "for i in tqdm_notebook(xrange(videos_len), desc=\"Preprocessing Videos\"):\n",
    "    path = video_paths[i]\n",
    "    create_clips(path)\n",
    "    create_frames(path)\n",
    "    create_spectrograms(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Read in Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels Shape: (1872, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "labels = pd.read_csv(\"./data/labels.csv\").as_matrix()\n",
    "print \"Labels Shape: {}\".format(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write label to image mapping file\n",
    "with open('data/audio_labels.txt', 'a') as f:\n",
    "    for label in labels:\n",
    "        vid_id = label[0]\n",
    "        clip_id = label[1]\n",
    "        value = 0 if label[2] == 0 else 1 \n",
    "        img_path = \"./data/audio/\" + vid_id + \"/\" + '%05d' % clip_id + \".png\"\n",
    "        line = img_path + \" \" + '%d' % value + \"\\n\"\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create Audio Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.36329\u001b[0m\u001b[0m | time: 36.637s\n",
      "| Adam | epoch: 004 | loss: 0.36329 - acc: 0.8292 -- iter: 2950/2995\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.35939\u001b[0m\u001b[0m | time: 38.083s\n",
      "| Adam | epoch: 004 | loss: 0.35939 - acc: 0.8303 | val_loss: 0.37591 - val_acc: 0.8171 -- iter: 2995/2995\n",
      "--\n",
      "INFO:tensorflow:/Users/logan/Documents/udacity/capstone/shot_audio.model is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_utils import image_preloader\n",
    "\n",
    "# Load path/class_id image file:\n",
    "dataset_file = 'data/audio_labels.txt'\n",
    "dataset_sample = 'data/audio_labels_sample.txt'\n",
    "\n",
    "# Build the preloader array, resize images to 300x300\n",
    "from tflearn.data_utils import image_preloader\n",
    "X, Y = image_preloader(dataset_file, \n",
    "                       image_shape=(32, 32),\n",
    "                       mode='file', \n",
    "                       categorical_labels=True,   \n",
    "                       normalize=True)\n",
    "\n",
    "# Real-time data preprocessing\n",
    "img_prep = ImagePreprocessing()\n",
    "img_prep.add_featurewise_zero_center()\n",
    "img_prep.add_featurewise_stdnorm()\n",
    "\n",
    "# Building convolutional network\n",
    "network = input_data(shape=[None, 32, 32, 3],\n",
    "                     data_preprocessing=img_prep)\n",
    "network = conv_2d(network, 32, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2)\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2)\n",
    "network = fully_connected(network, 512, activation='relu')\n",
    "network = dropout(network, 0.5)\n",
    "network = fully_connected(network, 2, activation='softmax')\n",
    "network = regression(network,\n",
    "                     optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     learning_rate=0.001)\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(network,tensorboard_verbose=3)\n",
    "model.fit(X, Y, \n",
    "          n_epoch=4,\n",
    "          snapshot_step=5, \n",
    "          show_metric=True,\n",
    "          validation_set=0.2,\n",
    "          batch_size=50,\n",
    "          shuffle=True,\n",
    "          run_id=\"audio-1\")\n",
    "\n",
    "model.save(\"shot_audio.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tn': 123, 'fp': 41, 'fn': 0, 'tp': 32}\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = image_preloader(dataset_sample, \n",
    "                       image_shape=(32, 32),\n",
    "                       mode='file', \n",
    "                       categorical_labels=True,   \n",
    "                       normalize=True)\n",
    "\n",
    "Y_predict = model.predict(X_test[:])\n",
    "\n",
    "m = {}\n",
    "for i in range(len(Y_predict)):\n",
    "    pred_0, pred_1 = int(round(Y_predict[i][0])), int(round(Y_predict[i][1]))\n",
    "    test_0, test_1 = int(round(Y_test[i][0])), int(round(Y_test[i][1]))\n",
    "    key = \"{}-{}-{}-{}\".format(pred_0, pred_1, test_0, test_1)\n",
    "    if key == '1-0-1-0':\n",
    "        key = \"tn\"\n",
    "    elif key == '0-1-0-1':\n",
    "        key = \"tp\"\n",
    "    elif key == '0-1-1-0':\n",
    "        key = \"fp\"\n",
    "    elif key == '1-0-0-1':\n",
    "        key = \"fn\"\n",
    "    if key in m:\n",
    "        m[key] += 1\n",
    "    else:\n",
    "        m[key] = 0\n",
    "\n",
    "print m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
